=== Training with Lr=0.01, Optimizer=SGD, Dropout=0.5 ===
c:\Users\MyBook Hype AMD\AppData\Local\Programs\Python\Python313\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
c:\Users\MyBook Hype AMD\AppData\Local\Programs\Python\Python313\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
c:\Users\MyBook Hype AMD\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1/10
----------
train Loss : 2.8966 Acc : 0.3419
val Loss : 1.7497 Acc : 0.4412
Epoch 2/10
----------
train Loss : 3.6876 Acc : 0.4375
val Loss : 4.2033 Acc : 0.2941
Epoch 3/10
----------
train Loss : 4.6965 Acc : 0.4412
val Loss : 1.3084 Acc : 0.6471
Epoch 4/10
----------
train Loss : 4.4853 Acc : 0.5110
val Loss : 1.5424 Acc : 0.6471
Epoch 5/10
----------
train Loss : 3.6433 Acc : 0.5515
val Loss : 1.8322 Acc : 0.5588
Epoch 6/10
----------
train Loss : 3.9091 Acc : 0.5680
val Loss : 2.5383 Acc : 0.7059
Epoch 7/10
----------
train Loss : 3.7923 Acc : 0.5846
val Loss : 1.4617 Acc : 0.6176
Epoch 8/10
----------
train Loss : 2.9034 Acc : 0.6213
val Loss : 0.8542 Acc : 0.7059
Epoch 9/10
----------
train Loss : 2.1417 Acc : 0.6599
val Loss : 0.6965 Acc : 0.7647
Epoch 10/10
----------
train Loss : 2.3179 Acc : 0.6507
val Loss : 0.6577 Acc : 0.7353
Best val acc: 0.764706

Final Validation Accuracy: 0.7353
Saved model to model_lr0.01_optSGD_drop0.5_acc0.7353.pth

=== Training with Lr=0.01, Optimizer=SGD, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 3.6996 Acc : 0.3051
val Loss : 3.3373 Acc : 0.5000
Epoch 2/10
----------
train Loss : 4.8637 Acc : 0.3603
val Loss : 4.2896 Acc : 0.2941
Epoch 3/10
----------
train Loss : 5.7917 Acc : 0.4393
val Loss : 3.2935 Acc : 0.5588
Epoch 4/10
----------
train Loss : 6.1822 Acc : 0.4412
val Loss : 3.3728 Acc : 0.5294
Epoch 5/10
----------
train Loss : 5.9488 Acc : 0.4210
val Loss : 2.5234 Acc : 0.5588
Epoch 6/10
----------
train Loss : 6.0892 Acc : 0.4798
val Loss : 1.6476 Acc : 0.6765
Epoch 7/10
----------
train Loss : 5.2451 Acc : 0.5221
val Loss : 3.7175 Acc : 0.5294
Epoch 8/10
----------
train Loss : 5.5600 Acc : 0.5294
val Loss : 2.1296 Acc : 0.6471
Epoch 9/10
----------
train Loss : 4.9286 Acc : 0.5404
val Loss : 1.7065 Acc : 0.6765
Epoch 10/10
----------
train Loss : 4.8123 Acc : 0.5349
val Loss : 1.2042 Acc : 0.7059
Best val acc: 0.705882

Final Validation Accuracy: 0.7059
Saved model to model_lr0.01_optSGD_drop0.6_acc0.7059.pth

=== Training with Lr=0.01, Optimizer=Adam, Dropout=0.5 ===
Epoch 1/10
----------
train Loss : 2.7937 Acc : 0.3824
val Loss : 3.9023 Acc : 0.4412
Epoch 2/10
----------
train Loss : 1.9164 Acc : 0.6250
val Loss : 1.2721 Acc : 0.6471
Epoch 3/10
----------
train Loss : 1.4817 Acc : 0.7040
val Loss : 2.3571 Acc : 0.5294
Epoch 4/10
----------
train Loss : 1.3250 Acc : 0.7408
val Loss : 2.0396 Acc : 0.5588
Epoch 5/10
----------
train Loss : 1.0775 Acc : 0.7684
val Loss : 1.2669 Acc : 0.7059
Epoch 6/10
----------
train Loss : 1.2473 Acc : 0.7721
val Loss : 0.7716 Acc : 0.8235
Epoch 7/10
----------
train Loss : 0.9976 Acc : 0.8143
val Loss : 1.0607 Acc : 0.7647
Epoch 8/10
----------
train Loss : 0.8663 Acc : 0.8217
val Loss : 1.6802 Acc : 0.7353
Epoch 9/10
----------
train Loss : 0.8495 Acc : 0.8290
val Loss : 1.3493 Acc : 0.7647
Epoch 10/10
----------
train Loss : 0.5755 Acc : 0.8658
val Loss : 1.2062 Acc : 0.7941
Best val acc: 0.823529

Final Validation Accuracy: 0.7941
Saved model to model_lr0.01_optAdam_drop0.5_acc0.7941.pth

=== Training with Lr=0.01, Optimizer=Adam, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 3.0505 Acc : 0.3676
val Loss : 1.7933 Acc : 0.4412
Epoch 2/10
----------
train Loss : 2.1324 Acc : 0.5735
val Loss : 2.3471 Acc : 0.5882
Epoch 3/10
----------
train Loss : 1.9271 Acc : 0.6581
val Loss : 1.4063 Acc : 0.6471
Epoch 4/10
----------
train Loss : 1.9442 Acc : 0.6599
val Loss : 1.2698 Acc : 0.7059
Epoch 5/10
----------
train Loss : 1.8408 Acc : 0.6820
val Loss : 1.8539 Acc : 0.7647
Epoch 6/10
----------
train Loss : 1.6157 Acc : 0.7206
val Loss : 1.2988 Acc : 0.6765
Epoch 7/10
----------
train Loss : 1.4018 Acc : 0.7665
val Loss : 1.0780 Acc : 0.7059
Epoch 8/10
----------
train Loss : 1.3594 Acc : 0.7574
val Loss : 1.4015 Acc : 0.6765
Epoch 9/10
----------
train Loss : 0.9568 Acc : 0.8070
val Loss : 1.2067 Acc : 0.6471
Epoch 10/10
----------
train Loss : 1.1713 Acc : 0.7757
val Loss : 0.9319 Acc : 0.7353
Best val acc: 0.764706

Final Validation Accuracy: 0.7353
Saved model to model_lr0.01_optAdam_drop0.6_acc0.7353.pth

=== Training with Lr=0.001, Optimizer=SGD, Dropout=0.5 ===
Epoch 1/10
----------
train Loss : 1.5174 Acc : 0.3585
val Loss : 0.9611 Acc : 0.5588
Epoch 2/10
----------
train Loss : 1.1608 Acc : 0.5441
val Loss : 0.8790 Acc : 0.6471
Epoch 3/10
----------
train Loss : 1.0144 Acc : 0.6103
val Loss : 0.8097 Acc : 0.6765
Epoch 4/10
----------
train Loss : 0.8769 Acc : 0.6673
val Loss : 0.7276 Acc : 0.7941
Epoch 5/10
----------
train Loss : 0.8906 Acc : 0.6765
val Loss : 0.6178 Acc : 0.8529
Epoch 6/10
----------
train Loss : 0.8218 Acc : 0.7151
val Loss : 0.5617 Acc : 0.7941
Epoch 7/10
----------
train Loss : 0.8079 Acc : 0.7188
val Loss : 0.7211 Acc : 0.7353
Epoch 8/10
----------
train Loss : 0.6763 Acc : 0.7812
val Loss : 0.5609 Acc : 0.7059
Epoch 9/10
----------
train Loss : 0.6225 Acc : 0.7739
val Loss : 0.5297 Acc : 0.7941
Epoch 10/10
----------
train Loss : 0.6095 Acc : 0.7610
val Loss : 0.4792 Acc : 0.8235
Best val acc: 0.852941

Final Validation Accuracy: 0.8235
Saved model to model_lr0.001_optSGD_drop0.5_acc0.8235.pth

=== Training with Lr=0.001, Optimizer=SGD, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 1.6681 Acc : 0.3180
val Loss : 1.1780 Acc : 0.5588
Epoch 2/10
----------
train Loss : 1.4018 Acc : 0.4743
val Loss : 0.9948 Acc : 0.5882
Epoch 3/10
----------
train Loss : 1.2965 Acc : 0.5092
val Loss : 0.9493 Acc : 0.6176
Epoch 4/10
----------
train Loss : 1.2171 Acc : 0.5460
val Loss : 0.8446 Acc : 0.7353
Epoch 5/10
----------
train Loss : 1.1929 Acc : 0.5717
val Loss : 0.8608 Acc : 0.6471
Epoch 6/10
----------
train Loss : 1.0228 Acc : 0.6268
val Loss : 0.7394 Acc : 0.7059
Epoch 7/10
----------
train Loss : 1.0941 Acc : 0.5993
val Loss : 0.8329 Acc : 0.7059
Epoch 8/10
----------
train Loss : 0.9888 Acc : 0.6397
val Loss : 0.7325 Acc : 0.7059
Epoch 9/10
----------
train Loss : 0.9951 Acc : 0.6471
val Loss : 0.7338 Acc : 0.7059
Epoch 10/10
----------
train Loss : 0.9728 Acc : 0.6360
val Loss : 0.7311 Acc : 0.6765
Best val acc: 0.735294

Final Validation Accuracy: 0.6765
Saved model to model_lr0.001_optSGD_drop0.6_acc0.6765.pth

=== Training with Lr=0.001, Optimizer=Adam, Dropout=0.5 ===
Epoch 1/10
----------
train Loss : 1.6318 Acc : 0.4945
val Loss : 0.8739 Acc : 0.6471
Epoch 2/10
----------
train Loss : 0.6993 Acc : 0.7353
val Loss : 0.5350 Acc : 0.7647
Epoch 3/10
----------
train Loss : 0.5181 Acc : 0.8070
val Loss : 0.4811 Acc : 0.7941
Epoch 4/10
----------
train Loss : 0.4027 Acc : 0.8621
val Loss : 0.3854 Acc : 0.8529
Epoch 5/10
----------
train Loss : 0.3525 Acc : 0.8750
val Loss : 1.1384 Acc : 0.7941
Epoch 6/10
----------
train Loss : 0.3053 Acc : 0.8824
val Loss : 0.4127 Acc : 0.7647
Epoch 7/10
----------
train Loss : 0.3025 Acc : 0.8842
val Loss : 0.7290 Acc : 0.7941
Epoch 8/10
----------
train Loss : 0.2816 Acc : 0.8934
val Loss : 0.5049 Acc : 0.8529
Epoch 9/10
----------
train Loss : 0.2625 Acc : 0.9228
val Loss : 0.4131 Acc : 0.8235
Epoch 10/10
----------
train Loss : 0.1486 Acc : 0.9467
val Loss : 0.3299 Acc : 0.8529
Best val acc: 0.852941

Final Validation Accuracy: 0.8529
Saved model to model_lr0.001_optAdam_drop0.5_acc0.8529.pth

=== Training with Lr=0.001, Optimizer=Adam, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 1.5728 Acc : 0.4651
val Loss : 0.8475 Acc : 0.6471
Epoch 2/10
----------
train Loss : 0.8981 Acc : 0.6801
val Loss : 0.8594 Acc : 0.6765
Epoch 3/10
----------
train Loss : 0.7459 Acc : 0.7188
val Loss : 0.6607 Acc : 0.7647
Epoch 4/10
----------
train Loss : 0.6478 Acc : 0.7592
val Loss : 0.5109 Acc : 0.7647
Epoch 5/10
----------
train Loss : 0.5517 Acc : 0.8051
val Loss : 0.5692 Acc : 0.7353
Epoch 6/10
----------
train Loss : 0.4520 Acc : 0.8162
val Loss : 0.5405 Acc : 0.7353
Epoch 7/10
----------
train Loss : 0.3924 Acc : 0.8695
val Loss : 0.3559 Acc : 0.8529
Epoch 8/10
----------
train Loss : 0.4251 Acc : 0.8732
val Loss : 0.3550 Acc : 0.8824
Epoch 9/10
----------
train Loss : 0.3668 Acc : 0.8566
val Loss : 0.5390 Acc : 0.7647
Epoch 10/10
----------
train Loss : 0.3017 Acc : 0.8879
val Loss : 0.4001 Acc : 0.8529
Best val acc: 0.882353

Final Validation Accuracy: 0.8529
Saved model to model_lr0.001_optAdam_drop0.6_acc0.8529.pth

=== Training with Lr=0.0001, Optimizer=SGD, Dropout=0.5 ===
Epoch 1/10
----------
train Loss : 1.7337 Acc : 0.2555
val Loss : 1.4982 Acc : 0.2353
Epoch 2/10
----------
train Loss : 1.4989 Acc : 0.3732
val Loss : 1.3493 Acc : 0.4118
Epoch 3/10
----------
train Loss : 1.4191 Acc : 0.4136
val Loss : 1.2417 Acc : 0.4412
Epoch 4/10
----------
train Loss : 1.3418 Acc : 0.4467
val Loss : 1.1822 Acc : 0.5000
Epoch 5/10
----------
train Loss : 1.2250 Acc : 0.4982
val Loss : 1.1376 Acc : 0.4412
Epoch 6/10
----------
train Loss : 1.1788 Acc : 0.5349
val Loss : 1.0407 Acc : 0.5588
Epoch 7/10
----------
train Loss : 1.1036 Acc : 0.5643
val Loss : 0.9972 Acc : 0.5588
Epoch 8/10
----------
train Loss : 1.0577 Acc : 0.5956
val Loss : 0.9695 Acc : 0.6176
Epoch 9/10
----------
train Loss : 1.0379 Acc : 0.5790
val Loss : 0.9557 Acc : 0.5588
Epoch 10/10
----------
train Loss : 0.9578 Acc : 0.6250
val Loss : 0.9247 Acc : 0.5882
Best val acc: 0.617647

Final Validation Accuracy: 0.5882
Saved model to model_lr0.0001_optSGD_drop0.5_acc0.5882.pth

=== Training with Lr=0.0001, Optimizer=SGD, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 1.8139 Acc : 0.2537
val Loss : 1.5817 Acc : 0.2353
Epoch 2/10
----------
train Loss : 1.6696 Acc : 0.2978
val Loss : 1.4956 Acc : 0.2647
Epoch 3/10
----------
train Loss : 1.5460 Acc : 0.3676
val Loss : 1.4111 Acc : 0.3235
Epoch 4/10
----------
train Loss : 1.5341 Acc : 0.3493
val Loss : 1.3787 Acc : 0.3824
Epoch 5/10
----------
train Loss : 1.4752 Acc : 0.3824
val Loss : 1.3104 Acc : 0.4412
Epoch 6/10
----------
train Loss : 1.4811 Acc : 0.4062
val Loss : 1.2891 Acc : 0.4118
Epoch 7/10
----------
train Loss : 1.3444 Acc : 0.4467
val Loss : 1.2196 Acc : 0.4412
Epoch 8/10
----------
train Loss : 1.3486 Acc : 0.4412
val Loss : 1.2046 Acc : 0.4706
Epoch 9/10
----------
train Loss : 1.3046 Acc : 0.4871
val Loss : 1.1578 Acc : 0.4706
Epoch 10/10
----------
train Loss : 1.2555 Acc : 0.5239
val Loss : 1.1087 Acc : 0.5294
Best val acc: 0.529412

Final Validation Accuracy: 0.5294
Saved model to model_lr0.0001_optSGD_drop0.6_acc0.5294.pth

=== Training with Lr=0.0001, Optimizer=Adam, Dropout=0.5 ===
Epoch 1/10
----------
train Loss : 1.5286 Acc : 0.3842
val Loss : 1.0324 Acc : 0.5882
Epoch 2/10
----------
train Loss : 1.0663 Acc : 0.5735
val Loss : 0.8059 Acc : 0.6471
Epoch 3/10
----------
train Loss : 0.7327 Acc : 0.7518
val Loss : 0.6763 Acc : 0.7647
Epoch 4/10
----------
train Loss : 0.6853 Acc : 0.7500
val Loss : 0.6879 Acc : 0.7059
Epoch 5/10
----------
train Loss : 0.5704 Acc : 0.7904
val Loss : 0.5828 Acc : 0.7353
Epoch 6/10
----------
train Loss : 0.4482 Acc : 0.8585
val Loss : 0.5557 Acc : 0.7647
Epoch 7/10
----------
train Loss : 0.4699 Acc : 0.8327
val Loss : 0.5228 Acc : 0.7059
Epoch 8/10
----------
train Loss : 0.3538 Acc : 0.8860
val Loss : 0.4080 Acc : 0.8824
Epoch 9/10
----------
train Loss : 0.3136 Acc : 0.8915
val Loss : 0.4368 Acc : 0.8235
Epoch 10/10
----------
train Loss : 0.3223 Acc : 0.8989
val Loss : 0.4672 Acc : 0.7941
Best val acc: 0.882353

Final Validation Accuracy: 0.7941
Saved model to model_lr0.0001_optAdam_drop0.5_acc0.7941.pth

=== Training with Lr=0.0001, Optimizer=Adam, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 1.6690 Acc : 0.2904
val Loss : 1.2453 Acc : 0.5588
Epoch 2/10
----------
train Loss : 1.2991 Acc : 0.4908
val Loss : 1.0169 Acc : 0.5882
Epoch 3/10
----------
train Loss : 1.1259 Acc : 0.5478
val Loss : 0.9452 Acc : 0.5882
Epoch 4/10
----------
train Loss : 0.9213 Acc : 0.6397
val Loss : 0.7929 Acc : 0.6471
Epoch 5/10
----------
train Loss : 0.8501 Acc : 0.6820
val Loss : 0.7676 Acc : 0.6765
Epoch 6/10
----------
train Loss : 0.7230 Acc : 0.7353
val Loss : 0.7451 Acc : 0.7059
Epoch 7/10
----------
train Loss : 0.6805 Acc : 0.7463
val Loss : 0.6926 Acc : 0.7353
Epoch 8/10
----------
train Loss : 0.6056 Acc : 0.7849
val Loss : 0.6001 Acc : 0.7647
Epoch 9/10
----------
train Loss : 0.5380 Acc : 0.8088
val Loss : 0.5864 Acc : 0.7353
Epoch 10/10
----------
train Loss : 0.5444 Acc : 0.8235
val Loss : 0.5542 Acc : 0.7059
Best val acc: 0.764706

Final Validation Accuracy: 0.7059
Saved model to model_lr0.0001_optAdam_drop0.6_acc0.7059.pth
Best Model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Dropout(p=0.5, inplace=False)
    (5): Linear(in_features=4096, out_features=1024, bias=True)
    (6): ReLU(inplace=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Dropout(p=0.5, inplace=False)
    (9): Linear(in_features=1024, out_features=5, bias=True)
  )
)
Best Parameters: {'learning_rate': 0.001, 'optimizer': 'Adam', 'dropout_rate': 0.5}
Best Validation Accuracy: 0.8529