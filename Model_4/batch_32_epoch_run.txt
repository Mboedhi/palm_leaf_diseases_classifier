=== Training with Lr=0.01, Optimizer=SGD, Dropout=0.5 ===
c:\Users\MyBook Hype AMD\AppData\Local\Programs\Python\Python313\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
c:\Users\MyBook Hype AMD\AppData\Local\Programs\Python\Python313\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
c:\Users\MyBook Hype AMD\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1/10
----------
train Loss : 1.7902 Acc : 0.3860
val Loss : 3.0338 Acc : 0.5000
Epoch 2/10
----------
train Loss : 1.8835 Acc : 0.4596
val Loss : 0.9163 Acc : 0.7353
Epoch 3/10
----------
train Loss : 1.8423 Acc : 0.5460
val Loss : 0.7876 Acc : 0.7647
Epoch 4/10
----------
train Loss : 1.7904 Acc : 0.6066
val Loss : 1.5132 Acc : 0.5588
Epoch 5/10
----------
train Loss : 1.6258 Acc : 0.6379
val Loss : 0.8969 Acc : 0.6471
Epoch 6/10
----------
train Loss : 1.6950 Acc : 0.6287
val Loss : 12.9681 Acc : 0.1765
Epoch 7/10
----------
train Loss : 1.4823 Acc : 0.6838
val Loss : 0.5162 Acc : 0.8235
Epoch 8/10
----------
train Loss : 1.6084 Acc : 0.6949
val Loss : 0.5016 Acc : 0.7941
Epoch 9/10
----------
train Loss : 1.2736 Acc : 0.6930
val Loss : 0.6978 Acc : 0.8235
Epoch 10/10
----------
train Loss : 1.2184 Acc : 0.7335
val Loss : 0.9053 Acc : 0.6765
Best val acc: 0.823529

Final Validation Accuracy: 0.6765
Saved model to model_lr0.01_optSGD_drop0.5_acc0.6765.pth

=== Training with Lr=0.01, Optimizer=SGD, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 1.8121 Acc : 0.3750
val Loss : 3.8280 Acc : 0.3235
Epoch 2/10
----------
train Loss : 2.5794 Acc : 0.4062
val Loss : 1.9265 Acc : 0.4706
Epoch 3/10
----------
train Loss : 2.5561 Acc : 0.4651
val Loss : 2.0358 Acc : 0.5294
Epoch 4/10
----------
train Loss : 2.9658 Acc : 0.4485
val Loss : 1.2257 Acc : 0.6765
Epoch 5/10
----------
train Loss : 3.2772 Acc : 0.4982
val Loss : 2.7052 Acc : 0.4706
Epoch 6/10
----------
train Loss : 2.6164 Acc : 0.5643
val Loss : 1.4280 Acc : 0.7353
Epoch 7/10
----------
train Loss : 2.5301 Acc : 0.5772
val Loss : 2.5432 Acc : 0.6471
Epoch 8/10
----------
train Loss : 3.0194 Acc : 0.5239
val Loss : 1.0374 Acc : 0.6471
Epoch 9/10
----------
train Loss : 2.5272 Acc : 0.5919
val Loss : 1.8832 Acc : 0.6176
Epoch 10/10
----------
train Loss : 2.3355 Acc : 0.6415
val Loss : 0.8214 Acc : 0.8235
Best val acc: 0.823529

Final Validation Accuracy: 0.8235
Saved model to model_lr0.01_optSGD_drop0.6_acc0.8235.pth

=== Training with Lr=0.01, Optimizer=Adam, Dropout=0.5 ===
Epoch 1/10
----------
train Loss : 2.4199 Acc : 0.4118
val Loss : 4.2346 Acc : 0.4118
Epoch 2/10
----------
train Loss : 1.2648 Acc : 0.6342
val Loss : 1.5488 Acc : 0.5882
Epoch 3/10
----------
train Loss : 0.9648 Acc : 0.7537
val Loss : 0.5212 Acc : 0.7353
Epoch 4/10
----------
train Loss : 0.6077 Acc : 0.8290
val Loss : 0.4791 Acc : 0.8235
Epoch 5/10
----------
train Loss : 0.5898 Acc : 0.8493
val Loss : 1.1094 Acc : 0.7941
Epoch 6/10
----------
train Loss : 0.4405 Acc : 0.8842
val Loss : 0.5810 Acc : 0.8529
Epoch 7/10
----------
train Loss : 0.5705 Acc : 0.8787
val Loss : 0.8622 Acc : 0.7353
Epoch 8/10
----------
train Loss : 0.4715 Acc : 0.8879
val Loss : 1.1770 Acc : 0.7647
Epoch 9/10
----------
train Loss : 0.2747 Acc : 0.9283
val Loss : 1.0382 Acc : 0.7647
Epoch 10/10
----------
train Loss : 0.3034 Acc : 0.9246
val Loss : 0.9043 Acc : 0.7941
Best val acc: 0.852941

Final Validation Accuracy: 0.7941
Saved model to model_lr0.01_optAdam_drop0.5_acc0.7941.pth

=== Training with Lr=0.01, Optimizer=Adam, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 2.5765 Acc : 0.3860
val Loss : 3.1260 Acc : 0.5588
Epoch 2/10
----------
train Loss : 1.6159 Acc : 0.5956
val Loss : 1.3990 Acc : 0.6176
Epoch 3/10
----------
train Loss : 1.3057 Acc : 0.7040
val Loss : 1.7241 Acc : 0.6471
Epoch 4/10
----------
train Loss : 1.2230 Acc : 0.7390
val Loss : 1.6346 Acc : 0.6471
Epoch 5/10
----------
train Loss : 1.0256 Acc : 0.7665
val Loss : 1.0935 Acc : 0.7353
Epoch 6/10
----------
train Loss : 0.8695 Acc : 0.8070
val Loss : 1.1876 Acc : 0.6765
Epoch 7/10
----------
train Loss : 0.9489 Acc : 0.7923
val Loss : 0.7953 Acc : 0.7941
Epoch 8/10
----------
train Loss : 0.5213 Acc : 0.8713
val Loss : 0.6363 Acc : 0.7941
Epoch 9/10
----------
train Loss : 0.7461 Acc : 0.8346
val Loss : 0.8058 Acc : 0.8235
Epoch 10/10
----------
train Loss : 0.8274 Acc : 0.8327
val Loss : 0.9819 Acc : 0.7941
Best val acc: 0.823529

Final Validation Accuracy: 0.7941
Saved model to model_lr0.01_optAdam_drop0.6_acc0.7941.pth

=== Training with Lr=0.001, Optimizer=SGD, Dropout=0.5 ===
Epoch 1/10
----------
train Loss : 1.7041 Acc : 0.3051
val Loss : 1.1862 Acc : 0.6471
Epoch 2/10
----------
train Loss : 1.2102 Acc : 0.5184
val Loss : 0.9863 Acc : 0.7059
Epoch 3/10
----------
train Loss : 0.9880 Acc : 0.6232
val Loss : 0.8305 Acc : 0.7647
Epoch 4/10
----------
train Loss : 0.8660 Acc : 0.6930
val Loss : 0.8634 Acc : 0.8235
Epoch 5/10
----------
train Loss : 0.8308 Acc : 0.6820
val Loss : 0.7433 Acc : 0.7059
Epoch 6/10
----------
train Loss : 0.7886 Acc : 0.7096
val Loss : 0.6500 Acc : 0.7941
Epoch 7/10
----------
train Loss : 0.7192 Acc : 0.7114
val Loss : 0.6416 Acc : 0.8235
Epoch 8/10
----------
train Loss : 0.6300 Acc : 0.7555
val Loss : 0.5934 Acc : 0.7647
Epoch 9/10
----------
train Loss : 0.5780 Acc : 0.7812
val Loss : 0.5596 Acc : 0.7941
Epoch 10/10
----------
train Loss : 0.5962 Acc : 0.7776
val Loss : 0.5577 Acc : 0.8235
Best val acc: 0.823529

Final Validation Accuracy: 0.8235
Saved model to model_lr0.001_optSGD_drop0.5_acc0.8235.pth

=== Training with Lr=0.001, Optimizer=SGD, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 1.7932 Acc : 0.2518
val Loss : 1.3524 Acc : 0.3235
Epoch 2/10
----------
train Loss : 1.4188 Acc : 0.4357
val Loss : 1.2278 Acc : 0.4412
Epoch 3/10
----------
train Loss : 1.2743 Acc : 0.4816
val Loss : 1.0984 Acc : 0.5882
Epoch 4/10
----------
train Loss : 1.1560 Acc : 0.5717
val Loss : 0.9665 Acc : 0.7059
Epoch 5/10
----------
train Loss : 1.0959 Acc : 0.5735
val Loss : 0.9079 Acc : 0.5882
Epoch 6/10
----------
train Loss : 1.1004 Acc : 0.5735
val Loss : 0.8415 Acc : 0.6176
Epoch 7/10
----------
train Loss : 1.0501 Acc : 0.5974
val Loss : 0.7943 Acc : 0.7059
Epoch 8/10
----------
train Loss : 0.9369 Acc : 0.6324
val Loss : 0.7949 Acc : 0.7353
Epoch 9/10
----------
train Loss : 0.9759 Acc : 0.6452
val Loss : 0.8181 Acc : 0.6471
Epoch 10/10
----------
train Loss : 0.8668 Acc : 0.6765
val Loss : 0.6976 Acc : 0.7353
Best val acc: 0.735294

Final Validation Accuracy: 0.7353
Saved model to model_lr0.001_optSGD_drop0.6_acc0.7353.pth

=== Training with Lr=0.001, Optimizer=Adam, Dropout=0.5 ===
Epoch 1/10
----------
train Loss : 1.6007 Acc : 0.5018
val Loss : 1.6307 Acc : 0.6176
Epoch 2/10
----------
train Loss : 0.6590 Acc : 0.7684
val Loss : 0.8731 Acc : 0.6765
Epoch 3/10
----------
train Loss : 0.3767 Acc : 0.8750
val Loss : 0.7558 Acc : 0.7059
Epoch 4/10
----------
train Loss : 0.3133 Acc : 0.8897
val Loss : 0.5569 Acc : 0.7941
Epoch 5/10
----------
train Loss : 0.2539 Acc : 0.8989
val Loss : 0.6102 Acc : 0.8235
Epoch 6/10
----------
train Loss : 0.1975 Acc : 0.9246
val Loss : 0.3397 Acc : 0.8529
Epoch 7/10
----------
train Loss : 0.1211 Acc : 0.9596
val Loss : 0.4684 Acc : 0.8235
Epoch 8/10
----------
train Loss : 0.1430 Acc : 0.9449
val Loss : 0.4661 Acc : 0.8235
Epoch 9/10
----------
train Loss : 0.1204 Acc : 0.9614
val Loss : 0.6031 Acc : 0.8529
Epoch 10/10
----------
train Loss : 0.1150 Acc : 0.9430
val Loss : 0.5630 Acc : 0.7941
Best val acc: 0.852941

Final Validation Accuracy: 0.7941
Saved model to model_lr0.001_optAdam_drop0.5_acc0.7941.pth

=== Training with Lr=0.001, Optimizer=Adam, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 1.6425 Acc : 0.4449
val Loss : 0.9377 Acc : 0.5882
Epoch 2/10
----------
train Loss : 0.9180 Acc : 0.6893
val Loss : 0.7491 Acc : 0.6765
Epoch 3/10
----------
train Loss : 0.6458 Acc : 0.7849
val Loss : 0.6377 Acc : 0.7353
Epoch 4/10
----------
train Loss : 0.4186 Acc : 0.8658
val Loss : 0.4760 Acc : 0.7941
Epoch 5/10
----------
train Loss : 0.3931 Acc : 0.8456
val Loss : 0.3742 Acc : 0.8529
Epoch 6/10
----------
train Loss : 0.3353 Acc : 0.8989
val Loss : 0.3420 Acc : 0.8235
Epoch 7/10
----------
train Loss : 0.3295 Acc : 0.8897
val Loss : 0.4169 Acc : 0.7647
Epoch 8/10
----------
train Loss : 0.2553 Acc : 0.9099
val Loss : 0.4491 Acc : 0.7941
Epoch 9/10
----------
train Loss : 0.2244 Acc : 0.9154
val Loss : 0.4819 Acc : 0.7647
Epoch 10/10
----------
train Loss : 0.2561 Acc : 0.9173
val Loss : 0.4026 Acc : 0.7941
Best val acc: 0.852941

Final Validation Accuracy: 0.7941
Saved model to model_lr0.001_optAdam_drop0.6_acc0.7941.pth

=== Training with Lr=0.0001, Optimizer=SGD, Dropout=0.5 ===
Epoch 1/10
----------
train Loss : 1.8223 Acc : 0.2279
val Loss : 1.4749 Acc : 0.3824
Epoch 2/10
----------
train Loss : 1.7244 Acc : 0.2463
val Loss : 1.3560 Acc : 0.4706
Epoch 3/10
----------
train Loss : 1.5597 Acc : 0.3382
val Loss : 1.2748 Acc : 0.5000
Epoch 4/10
----------
train Loss : 1.4287 Acc : 0.3971
val Loss : 1.2178 Acc : 0.5882
Epoch 5/10
----------
train Loss : 1.4032 Acc : 0.4393
val Loss : 1.1713 Acc : 0.6471
Epoch 6/10
----------
train Loss : 1.2788 Acc : 0.4926
val Loss : 1.1318 Acc : 0.6765
Epoch 7/10
----------
train Loss : 1.3068 Acc : 0.4540
val Loss : 1.1066 Acc : 0.6471
Epoch 8/10
----------
train Loss : 1.2769 Acc : 0.4743
val Loss : 1.0628 Acc : 0.7059
Epoch 9/10
----------
train Loss : 1.2687 Acc : 0.4871
val Loss : 1.0227 Acc : 0.6471
Epoch 10/10
----------
train Loss : 1.1428 Acc : 0.5404
val Loss : 0.9985 Acc : 0.6765
Best val acc: 0.705882

Final Validation Accuracy: 0.6765
Saved model to model_lr0.0001_optSGD_drop0.5_acc0.6765.pth

=== Training with Lr=0.0001, Optimizer=SGD, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 1.8834 Acc : 0.1985
val Loss : 1.5707 Acc : 0.3235
Epoch 2/10
----------
train Loss : 1.8018 Acc : 0.2243
val Loss : 1.5024 Acc : 0.3824
Epoch 3/10
----------
train Loss : 1.7285 Acc : 0.2739
val Loss : 1.4525 Acc : 0.2941
Epoch 4/10
----------
train Loss : 1.6354 Acc : 0.3199
val Loss : 1.4150 Acc : 0.2941
Epoch 5/10
----------
train Loss : 1.6211 Acc : 0.3364
val Loss : 1.3555 Acc : 0.4412
Epoch 6/10
----------
train Loss : 1.5629 Acc : 0.3585
val Loss : 1.3211 Acc : 0.4706
Epoch 7/10
----------
train Loss : 1.4846 Acc : 0.3934
val Loss : 1.2848 Acc : 0.4706
Epoch 8/10
----------
train Loss : 1.4651 Acc : 0.3805
val Loss : 1.2661 Acc : 0.5000
Epoch 9/10
----------
train Loss : 1.4783 Acc : 0.3787
val Loss : 1.2211 Acc : 0.5000
Epoch 10/10
----------
train Loss : 1.4257 Acc : 0.4007
val Loss : 1.2187 Acc : 0.5000
Best val acc: 0.500000

Final Validation Accuracy: 0.5000
Saved model to model_lr0.0001_optSGD_drop0.6_acc0.5000.pth

=== Training with Lr=0.0001, Optimizer=Adam, Dropout=0.5 ===
Epoch 1/10
----------
train Loss : 1.5560 Acc : 0.3456
val Loss : 1.0356 Acc : 0.5588
Epoch 2/10
----------
train Loss : 1.1021 Acc : 0.5882
val Loss : 0.8995 Acc : 0.6176
Epoch 3/10
----------
train Loss : 0.7964 Acc : 0.6949
val Loss : 0.7488 Acc : 0.7059
Epoch 4/10
----------
train Loss : 0.6784 Acc : 0.7647
val Loss : 0.6440 Acc : 0.7941
Epoch 5/10
----------
train Loss : 0.5531 Acc : 0.8088
val Loss : 0.5650 Acc : 0.7941
Epoch 6/10
----------
train Loss : 0.4612 Acc : 0.8658
val Loss : 0.5248 Acc : 0.8235
Epoch 7/10
----------
train Loss : 0.4159 Acc : 0.8621
val Loss : 0.4901 Acc : 0.8235
Epoch 8/10
----------
train Loss : 0.3409 Acc : 0.8897
val Loss : 0.4408 Acc : 0.8529
Epoch 9/10
----------
train Loss : 0.2884 Acc : 0.9081
val Loss : 0.4540 Acc : 0.8529
Epoch 10/10
----------
train Loss : 0.2845 Acc : 0.9118
val Loss : 0.4361 Acc : 0.8529
Best val acc: 0.852941

Final Validation Accuracy: 0.8529
Saved model to model_lr0.0001_optAdam_drop0.5_acc0.8529.pth

=== Training with Lr=0.0001, Optimizer=Adam, Dropout=0.6 ===
Epoch 1/10
----------
train Loss : 1.7328 Acc : 0.2960
val Loss : 1.2184 Acc : 0.5000
Epoch 2/10
----------
train Loss : 1.3715 Acc : 0.4577
val Loss : 1.0787 Acc : 0.5588
Epoch 3/10
----------
train Loss : 1.1619 Acc : 0.5221
val Loss : 0.9288 Acc : 0.5882
Epoch 4/10
----------
train Loss : 1.0168 Acc : 0.6250
val Loss : 0.8775 Acc : 0.6471
Epoch 5/10
----------
train Loss : 0.8505 Acc : 0.6875
val Loss : 0.8163 Acc : 0.6471
Epoch 6/10
----------
train Loss : 0.7845 Acc : 0.7114
val Loss : 0.7689 Acc : 0.6471
Epoch 7/10
----------
train Loss : 0.6625 Acc : 0.7941
val Loss : 0.7130 Acc : 0.7353
Epoch 8/10
----------
train Loss : 0.6508 Acc : 0.7555
val Loss : 0.6731 Acc : 0.7059
Epoch 9/10
----------
train Loss : 0.5733 Acc : 0.7868
val Loss : 0.6254 Acc : 0.7353
Epoch 10/10
----------
train Loss : 0.5557 Acc : 0.8015
val Loss : 0.5850 Acc : 0.7647
Best val acc: 0.764706

Final Validation Accuracy: 0.7647
Saved model to model_lr0.0001_optAdam_drop0.6_acc0.7647.pth
Best Model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Dropout(p=0.5, inplace=False)
    (5): Linear(in_features=4096, out_features=1024, bias=True)
    (6): ReLU(inplace=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Dropout(p=0.5, inplace=False)
    (9): Linear(in_features=1024, out_features=5, bias=True)
  )
)
Best Parameters: {'learning_rate': 0.0001, 'optimizer': 'Adam', 'dropout_rate': 0.5}
Best Validation Accuracy: 0.8529